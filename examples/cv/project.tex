%-------------------------------------------------------------------------------
%	SECTION TITLE
%-------------------------------------------------------------------------------
\cvsection{Research/Projects}


%-------------------------------------------------------------------------------
%	CONTENT
%-------------------------------------------------------------------------------
My research interest includes computational geophysics and parallel algorithms. I'm experienced in parallel algorithm designs on modern computer architectures like GPU, multi-core CPU, and FPGA processors to solve the computational challenge raised from geoscience applications. Participated projects include:

\begin{cventries}

%---------------------------------------------------------
  \cventry
    {Core member} % Job title
    {Refactoring and Optimizing the Community Atmosphere Model (CAM) on the New Sunway Manycore Supercomputer} % Organization
    {Project} % Location
    {Jul. 2015 - Apr. 2016} % Date(s)
    {
      \begin{cvitems} % Description(s) of tasks/responsibilities
        \item {We refactor and optimize the Community Atmosphere Model (CAM) on the new Sunway many-core supercomputer of China, which is the rank 1 supercomputer in the latest Top 500 announcement. It uses a many-core processor that consists of management processing elements (MPEs) and clusters of computing processing elements (CPEs). To tackle the major challenges of mapping the large code base of CAM to the millions of cores on the Sunway system, we take OpenACC-based refactorization as the major tool, and apply source-to-source translator tools to generate the most suitable parallelism for the CPE cluster, and to fit the intermediate variable into the limited on-chip fast buffer. For single kernels, when comparing the originally ported version using only MPEs and the refactorized version using both the MPE and CPE clusters, we achieve up to 22x speedup for the compute-intensive kernels. For the 25km resolution CAM global model, we manage to scale to 24,000 MPEs, and 1,536,000 CPEs and achieve a simulation speed of 2.81 model years per day.}
      \end{cvitems}
    }

%---------------------------------------------------------
  \cventry
    {Project leader, cooperated with China Financial Future Exchange (CFFEX)} % Job title
    {An Extremely Low-latency Market Server on Reconfigurable Platforms} % Organization
    {Project} % Location
    {May. 2015 - Jun. 2016} % Date(s)
    {
      \begin{cvitems} % Description(s) of tasks/responsibilities
        \item {We design an FPGA-based accelerated approach to market data processing, with an FPGA connected directly to the network to parse, split, filter the financial packets, and then push the market data feeds directly to the network after reconstructions of order books. Such a solution offers flexibility, as the FPGA can be reconfigured for different protocols and market processing logic, and high throughput with extremely low latency by eliminating the operating system's interrupts and network stacks. This paper also presents a novel CPU-FPGA hybrid database design which supports fast add/delete/update/query operations with minimal resource costs. Our system demonstrates its functionalities using the latest Maxeler ISCA data flow engine in the data center of China Financial Futures Exchange (CFFEX). Tested with over 70 millions of packets from CFFEX and compared with its existing software platform, our system supports over 200 instruments in an FPGA, with a constant latency, irrespective of throughputs, of $3\mu s$, archiving a speedup of 33x.}
      \end{cvitems}
    }

%---------------------------------------------------------
  \cventry
    {Topic leader} % type
    {Ensemble Full Waveform Inversion with Source Encoding} % Title
    {Research} %
    {Sep. 2014 - Jun. 2015} % Date(s)
    {
      \begin{cvitems} % Description(s) of tasks/responsibilities
        \item {Full waveform inversion (FWI) suffers from convergence toward local minima because of the inaccuracy of the initial model and the lack of low frequency data. Noises in seismograms further deteriorate the imaging quality. To relax the dependency on high-quality low-frequency data, we present an ensemble full waveform inversion method with source encoding (EnFWI), which is an ensemble approximation of the total inversion proposed by Tarantola. The method refines the velocity model iteratively by incorporating the observation, while the nonlinear evolution of the covariance is approximated by ensemble covariance. Encoded simultaneous-source FWI (ESSFWI) is applied to improve the representation for the low rank ensemble approximation, and to increase the rate of convergence. Experiments show that EnFWI achieves larger convergence range and better tolerance to data noise with less computational costs than traditional FWI methods.}
        \item {Related work is published in SEG2016}
      \end{cvitems}
    }

%---------------------------------------------------------
  \cventry
    {Topic leader} % Job title
    {A Fully-Pipelined Hardware Design for Gaussian Mixture Models} % Title
    {Research} % Location
    {Apr. 2014 - Nov. 2015} % Date(s)
    {
      \begin{cvitems} % Description(s) of tasks/responsibilities
        \item {Gaussian Mixture Models (GMMs) are widely used in many applications such as data mining, signal processing and computer vision, for probability density modeling and soft clustering. However, the parameters of a GMM need to be estimated from data by, for example, the Expectation-Maximization algorithm for Gaussian Mixture Models (EM-GMM), which is computationally demanding. This paper presents a novel solution to the EM-GMM algorithm targeting reconfigurable platforms, with five main contributions.  First, a pipeline-friendly EM-GMM algorithm that can easily be mapped to a fully pipelined hardware architecture. Second, a function evaluation unit for Gaussian probability density based on fixed-point arithmetic. Third, to cover a broad range of configurations from real applications, our approach is extended to support large scales of dimensions or/and components by fitting multiple pieces of smaller dimensions onto an FPGA chip. Fourth, we derive a cost and performance model that estimates possible logic resources, given a set of configurations. Fifth, experiments that need more than 20 minutes on a single core CPU, only take seconds to finish in our data flow engine.  Our design provides a practical solution to applications for training and explores better parameters for GMMs with hundreds of millions of high dimensional input instances, for low-latency and high-performance applications.}
      \end{cvitems}
    }

%---------------------------------------------------------
  \cventry
    {Project leader} % Job title
    {A CPU-GPU Hybrid Parallel Design for Beam Migration} % Organization
    {Project} % Location
    {Sep. 2013 - Dec. 2014} % Date(s)
    {
      \begin{cvitems} % Description(s) of tasks/responsibilities
        \item {The Kirchhoff beam-stack migration is quite popular in production with both better image quality and faster speed compared to Kirchhoff migration.  However, the beam forming step and beam mapping step are still expensive. Meanwhile, continuous High Performance Computing (HPC) developments offer new opportunities for the industry to further enhance the efficiency of beam migration methods. We present a design of a highly efficient CPU-GPU hybrid beam migration.  By parallelizing both the beam forming and the beam mapping routines with millions of GPU threads and using an asynchronous IO scheme, we derive a parallel beam migration design that fits current CPU-GPU hybrid clusters.  Then, we test our GPU-based beam migration on the SEG/EAGE salt model and the SEAM salt model for different generations of GPU architectures, presenting accurate imaging results with 4-12 times speedup compared to a parallel 16-core CPU design. The significant performance improvement would further close the gap to an interactive migration engine.}
        \item {Related work is published in EAGE2015}
      \end{cvitems}
    }

%---------------------------------------------------------
  \cventry
    {Improve the performance of the code} % Job title
    {Accelerating the Global Vegetation-Precipitation Correlation Algorithm} % Organization
    {Research} % Location
    {Sep. 2013 - Nov. 2013} % Date(s)
    {
      \begin{cvitems} % Description(s) of tasks/responsibilities
        \item {Startup Project for Ph.D. candidate cooperated with a Professor in Remote Sensing field, aiming to accelerate the algorithm taking months to finish. Optimization strategies for it include modifying the algorithm to reduce I/O accessing by utilizing local buffer, adding a memory pool to reduce frequent memory allocation/destruction, overlapping I/O transferring and computing. It gained 20x speedup in the end.}
        \item {Related work is published in the journal of Remote Sensing}
      \end{cvitems}
      %\begin{cvsubentries}
      %  \cvsubentry{}{KNOX(Solution for Enterprise Mobile Security) Penetration Testing}{Sep. 2013}{}
      %  \cvsubentry{}{Smart TV Penetration Testing}{Mar. 2011 - Oct. 2011}{}
      %\end{cvsubentries}
    }

%---------------------------------------------------------
\end{cventries}
